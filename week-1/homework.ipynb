{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bcf53a2",
   "metadata": {},
   "source": [
    "Q1. Downloading the data\n",
    "\n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2022.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "A: 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132c23f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-16 15:38:42--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.64.100.55, 18.64.100.144, 18.64.100.74, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.64.100.55|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 38139949 (36M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2022-01.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  36,37M  5,18MB/s    in 8,4s    \n",
      "\n",
      "2023-05-16 15:38:50 (4,34 MB/s) - ‘yellow_tripdata_2022-01.parquet’ saved [38139949/38139949]\n",
      "\n",
      "--2023-05-16 15:38:51--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.64.100.55, 18.64.100.144, 18.64.100.74, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.64.100.55|:443... failed: Connection refused.\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.64.100.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45616512 (44M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2022-02.parquet’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  43,50M  4,79MB/s    in 8,7s    \n",
      "\n",
      "2023-05-16 15:39:00 (5,00 MB/s) - ‘yellow_tripdata_2022-02.parquet’ saved [45616512/45616512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet\"\n",
    "!wget \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e1761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv yellow_tripdata_2022-01.parquet data/\n",
    "!mv yellow_tripdata_2022-02.parquet data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eea5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0ff53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e76577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abf1ffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns using shape: 19\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/yellow_tripdata_2022-01.parquet')\n",
    "# Using .shape\n",
    "num_of_columns = df.shape[1]\n",
    "print('Number of columns using shape:', num_of_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4793e459",
   "metadata": {},
   "source": [
    "Q2. Computing duration\n",
    "\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "A: 46.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf297cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:35:40</td>\n",
       "      <td>2022-01-01 00:53:29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:33:43</td>\n",
       "      <td>2022-01-01 00:42:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:53:21</td>\n",
       "      <td>2022-01-01 01:02:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:25:21</td>\n",
       "      <td>2022-01-01 00:35:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:36:48</td>\n",
       "      <td>2022-01-01 01:14:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0   \n",
       "1         1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0   \n",
       "2         2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0   \n",
       "3         2  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0   \n",
       "4         2  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.80         1.0                  N           142           236   \n",
       "1           2.10         1.0                  N           236            42   \n",
       "2           0.97         1.0                  N           166           166   \n",
       "3           1.09         1.0                  N           114            68   \n",
       "4           4.30         1.0                  N            68           163   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         14.5    3.0      0.5        3.65           0.0   \n",
       "1             1          8.0    0.5      0.5        4.00           0.0   \n",
       "2             1          7.5    0.5      0.5        1.76           0.0   \n",
       "3             2          8.0    0.5      0.5        0.00           0.0   \n",
       "4             1         23.5    0.5      0.5        3.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         21.95                   2.5          0.0  \n",
       "1                    0.3         13.30                   0.0          0.0  \n",
       "2                    0.3         10.56                   0.0          0.0  \n",
       "3                    0.3         11.80                   2.5          0.0  \n",
       "4                    0.3         30.30                   2.5          0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32236af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new duration field in minutes\n",
    "df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbf9455b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.463931e+06\n",
       "mean     1.421220e+01\n",
       "std      4.644531e+01\n",
       "min     -3.442400e+03\n",
       "50%      1.018333e+01\n",
       "95%      3.193333e+01\n",
       "98%      4.215000e+01\n",
       "99%      5.085000e+01\n",
       "max      8.513183e+03\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duration.describe(percentiles=[0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc703168",
   "metadata": {},
   "source": [
    "Q3. Dropping outliers\n",
    "\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "A: 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "842e24ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.421440e+06\n",
       "mean     1.267128e+01\n",
       "std      8.999282e+00\n",
       "min      1.000000e+00\n",
       "50%      1.023333e+01\n",
       "95%      3.105000e+01\n",
       "98%      3.971667e+01\n",
       "99%      4.568333e+01\n",
       "max      6.000000e+01\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the data which belongs to 98%/99% percentile\n",
    "df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "df.duration.describe(percentiles=[0.95,0.98,0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ae4a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827547930522406"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.421440e+06 / 2.463931e+06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ecd55",
   "metadata": {},
   "source": [
    "Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "    Turn the dataframe into a list of dictionaries\n",
    "    Fit a dictionary vectorizer\n",
    "    Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "A: 515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8f62019",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "categorical = ['PULocationID','DOLocationID']\n",
    "df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "# Create train dictonary and vectorize it\n",
    "train_dicts = df[categorical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e79ba8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dimensionality of the feature matrix\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21c1d7",
   "metadata": {},
   "source": [
    "Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "    Train a plain linear regression model with default parameters\n",
    "    Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "A: 6.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dbf28854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target\n",
    "target = 'duration'\n",
    "y_train = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b82ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model and predict\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00492d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.986190814952337"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into RMSE\n",
    "mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d250e",
   "metadata": {},
   "source": [
    "Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2022).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "A: 7.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e942d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_parquet('./data/yellow_tripdata_2022-02.parquet')\n",
    "\n",
    "# Create new duration field in minutes\n",
    "df_val['duration'] = df_val.tpep_dropoff_datetime - df_val.tpep_pickup_datetime\n",
    "df_val.duration = df_val.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    \n",
    "# Select the data which belongs to 98%/99% percentile\n",
    "df_val = df_val[(df_val.duration >= 1) & (df_val.duration <= 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd70b37",
   "metadata": {},
   "source": [
    "#Error with the fit transform for the validation df\n",
    "The issue here may be related to the use of the fit_transform() function on your validation set.\n",
    "\n",
    "The fit_transform() function first fits the vectorizer to the data and then transforms the data.\n",
    "When you fit the vectorizer to your validation set, it learns a new vocabulary,\n",
    "which may be different from the one it would learn from the training set.\n",
    "In particular, if the validation set doesn't contain all the categories present in the training set for the given features,\n",
    "this could lead to a difference in the number of columns when the data is one-hot encoded.\n",
    "\n",
    "The common practice is to fit() the vectorizer on the training data and then use transform()\n",
    "on the validation and test data.\n",
    "This way, the same vocabulary (i.e., the same set of categories) is used across all datasets.\n",
    "\n",
    "CODE:\n",
    "#Fit vectorizer on training data (replace df_train with your actual training data)\n",
    "train_dicts = df[categorical].to_dict(orient='records')\n",
    "dv.fit(train_dicts)\n",
    "\n",
    "#Transform validation data\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "#Print the dimensionality of the feature matrix\n",
    "print(X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ade5816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Categorical\n",
    "categorical = ['PULocationID','DOLocationID']\n",
    "df_val[categorical] = df_val[categorical].astype(str)\n",
    "\n",
    "# Create validation dictonary and vectorize it\n",
    "val_dicts = df_val[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# Define target\n",
    "target = 'duration'\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "781fa037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the dimensionality of the feature matrix\n",
    "X_val.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bda340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "y_val_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "360536ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.786407163179794"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into RMSE\n",
    "mean_squared_error(y_val, y_val_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23be74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
